# PostBuild Code Analysis Agent - Complete Documentation

## Overview

The **PostBuild Code Analysis Agent** is an AI-powered automated code analysis system designed to evaluate Python projects after build completion. It generates comprehensive, machine-readable and human-readable reports covering code quality, security, test coverage, and compliance with configurable coding standards. The system is especially useful for CI/CD pipelines and development teams seeking to maintain high code quality and catch issues early in the development lifecycle.

## The Problem

Development teams face several critical challenges in maintaining code quality:

- **Fragmented Analysis**: Multiple tools (flake8, bandit, pytest, coverage) produce disparate reports that developers must manually correlate
- **Late Detection**: Code quality issues are discovered late in the development cycle, requiring costly rework
- **Manual Effort**: Teams spend significant time analyzing build logs and test failures to identify root causes
- **Inconsistent Standards**: Without centralized enforcement, coding standards drift and inconsistencies accumulate
- **Security Blind Spots**: Security vulnerabilities can be overlooked among hundreds of other issues
- **Poor Visibility**: Non-technical stakeholders lack clear insights into project health and risks
- **Scalability Issues**: Manual analysis doesn't scale with large codebases or multiple projects

## The Solution: PostBuild Code Analysis Agent

The PostBuild Code Analysis Agent automates the entire post-build analysis pipeline with these key capabilities:

### Core Features

**Unified Analysis Engine**
- Consolidates results from multiple analysis tools (flake8, bandit, pytest, coverage)
- Analyzes build logs for failure patterns and error signatures
- Performs AST-based code inspection for structural issues
- Validates against configurable coding standards

**Intelligent Reporting**
- Generates machine-readable JSON reports optimized for automation and integration
- Produces human-readable Markdown reports with actionable recommendations
- Prioritizes findings by severity (critical, high, medium, low)
- Includes evidence, context, and specific remediation guidance

**Configurable Coding Standards**
- Function/method length limits and complexity thresholds
- Naming conventions for classes, functions, and constants
- Documentation requirements (docstrings)
- File structure standards
- Import organization rules
- Custom severity mappings for each violation type

**Security Integration**
- Detects CWE (Common Weakness Enumeration) vulnerabilities
- Flags security anti-patterns and risky code
- Prioritizes security findings for immediate attention
- Provides remediation paths for known vulnerabilities

**Test & Coverage Analysis**
- Identifies failing tests with root cause analysis
- Detects code coverage gaps at the file level
- Tracks test execution trends
- Recommends high-priority test gaps to address

### Key Benefits

âœ… **Proactive Quality Control**: Issues are detected and reported immediately after build completion

âœ… **Reduced Debugging Time**: Root cause analysis helps developers quickly understand build failures

âœ… **Automated Enforcement**: Coding standards are automatically checked without manual review

âœ… **Security Focus**: Security vulnerabilities are prioritized and escalated

âœ… **Better Metrics**: Clear, quantifiable metrics on code quality and test coverage

âœ… **Integration Ready**: JSON output integrates seamlessly with other tools and dashboards

âœ… **Developer Friendly**: Markdown reports provide clear, actionable recommendations

âœ… **Audit Trail**: All analysis results are logged and timestamped for compliance tracking

âœ… **Flexible Configuration**: Standards and thresholds can be customized per project

âœ… **Cost Effective**: No additional tool licenses needed; works with standard open-source tools

## How It Works (High-Level Flow)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Build Completion                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼            â–¼            â–¼
    Build Log   Test Results   Coverage Data
        â”‚            â”‚            â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                â”‚                â”‚
    â–¼                â–¼                â–¼
  Linting       Security        Static
  Analysis      Scanning        Analysis
    â”‚                â”‚                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚            â”‚            â”‚
        â–¼            â–¼            â–¼
    Source Code   Coding Standards   Code Quality
    Inspection    Validation         Analysis
        â”‚            â”‚                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                         â–¼
   Machine Report           Human Report
   (machine_report.json)    (human_report.md)
        â”‚                         â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                         â–¼
   Developers              CI/CD Pipeline
   (Review & Fix)          (Automation)
```

### Detailed Process Steps

1. **Data Ingestion**
   - Reads build logs, test results, coverage reports, and static analysis outputs
   - Loads configurable standards from config.yaml
   - Retrieves git commit information and repository metadata

2. **Analysis Phase**
   - **Build Analysis**: Parses build logs for error patterns (SyntaxError, ImportError, etc.)
   - **Test Analysis**: Categorizes test failures and calculates pass rates
   - **Coverage Analysis**: Identifies files below coverage thresholds
   - **Security Analysis**: Extracts CWE vulnerabilities and security risks
   - **Linting Analysis**: Processes flake8, mypy, and other linter outputs
   - **Coding Standards**: AST-based validation of naming conventions, function length, docstrings, etc.

3. **Finding Generation**
   - Each issue is converted to a structured "Finding" with:
     - Unique ID and descriptive title
     - Category (bug, security, style, test_gap, maintainability, etc.)
     - Severity level (critical, high, medium, low)
     - Detailed description with context
     - Evidence with file locations and code excerpts
     - Specific, actionable recommendations
     - Confidence score

4. **Report Generation**
   - **Machine Report**: JSON structure optimized for parsing and integration
   - **Human Report**: Markdown with severity badges, summaries, and detailed findings

5. **Output Delivery**
   - Reports saved to configurable output directory
   - Available for developer review, dashboard integration, or archival

## Project Architecture

### Component Overview

```
postbuild-analyzer/
â”œâ”€â”€ analyzer/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ postbuild_analyzer.py      # Core analysis engine (742 lines)
â”‚   â””â”€â”€ utils.py                   # Utility functions
â”‚
â”œâ”€â”€ sample_project/                # Example Python project
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ sample_module.py       # Example code with issues
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ test_sample.py         # Unit tests
â”‚
â”œâ”€â”€ reports/                       # Generated reports
â”‚   â”œâ”€â”€ build.log
â”‚   â”œâ”€â”€ test_results.json
â”‚   â”œâ”€â”€ coverage_report.json
â”‚   â”œâ”€â”€ static_analysis.json
â”‚   â”œâ”€â”€ machine_report.json        # Generated output
â”‚   â”œâ”€â”€ human_report.md            # Generated output
â”‚   â””â”€â”€ machine_report_example.json
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ analyze.yml                # GitHub Actions automation
â”‚
â”œâ”€â”€ run_local_analysis.py          # Local development script
â”œâ”€â”€ config.yaml                    # Configurable standards & thresholds
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ pytest.ini                     # Pytest configuration
â”œâ”€â”€ setup.py                       # Package setup
â”œâ”€â”€ README.md                      # Quick reference
â”œâ”€â”€ QUICKSTART.md                  # Getting started guide
â””â”€â”€ INDEX.md                       # Documentation index
```

### Core Analysis Engine

**File**: `analyzer/postbuild_analyzer.py`

**Key Classes**:

- `Finding`: Data class representing a single code analysis finding
- `PostBuildAnalyzer`: Main analyzer class orchestrating all analysis phases

**Key Methods**:

- `analyze()`: Executes complete analysis pipeline and returns reports
- `_analyze_build()`: Parses build logs for failures and errors
- `_analyze_tests()`: Processes test results and identifies failures
- `_analyze_coverage()`: Detects coverage gaps and below-threshold files
- `_analyze_static_analysis()`: Aggregates linting and security results
- `_analyze_coding_standards()`: Validates code against configurable standards
- `_analyze_code_quality()`: Performs deeper quality inspections
- `_generate_machine_report()`: Creates JSON report structure
- `_generate_human_report()`: Creates Markdown report with formatting
- `save_reports()`: Writes reports to disk

### Configuration System

**File**: `config.yaml`

Controls all analysis behavior:

```yaml
# Thresholds
coverage_threshold: 80              # Minimum coverage percentage
complexity_threshold: 10            # Max function complexity

# Feature Flags
enable_security_scan: true
enable_coding_standards_check: true
enable_coverage_analysis: true

# Coding Standards Configuration
coding_standards:
  max_function_lines: 50
  max_function_complexity: 10
  naming_conventions:
    class_pattern: "^[A-Z][a-zA-Z0-9]*$"      # PascalCase
    function_pattern: "^[a-z_][a-z0-9_]*$"    # snake_case
    constant_pattern: "^[A-Z_][A-Z0-9_]*$"    # UPPER_CASE
  docstring_required: true
  max_file_lines: 500
  max_nested_levels: 4
```

All configuration is optional with sensible defaults.

## Implementation Details

### Analysis Categories

Each finding is classified into one of these categories:

| Category | Description | Examples |
|----------|-------------|----------|
| **bug** | Logical errors or incorrect implementations | Failing tests, syntax errors, undefined variables |
| **security** | Vulnerabilities and security risks | SQL injection, hardcoded credentials, insecure deserialization |
| **style** | Code style and formatting issues | Naming conventions, trailing whitespace, import ordering |
| **test_gap** | Insufficient test coverage or missing tests | Low coverage files, untested code paths |
| **maintainability** | Code structure and maintenance issues | High complexity, long functions, missing documentation |
| **performance** | Performance-related concerns | Inefficient algorithms, unnecessary operations |

### Severity Levels

| Severity | Meaning | Action |
|----------|---------|--------|
| **critical** | Must be fixed before merge | Build failures, security vulnerabilities, failing tests |
| **high** | Should be fixed before merge | Low coverage, high complexity, security warnings |
| **medium** | Should be addressed soon | Style violations, maintainability concerns |
| **low** | Consider addressing | Minor style issues, documentation gaps |

### Confidence Scoring

Each finding includes a confidence score (0.0 - 1.0) indicating how certain the analyzer is:

- `1.0`: Definitive (test failures, coverage data)
- `0.9`: Very high confidence (security vulnerabilities, explicit violations)
- `0.85`: High confidence (parsed errors, explicit issues)
- `0.8`: Good confidence (linting issues, parsed patterns)
- `0.75`: Reasonable confidence (AST-based checks, pattern matching)

## Usage Scenarios

### Scenario 1: CI/CD Pipeline Integration

```bash
# In GitHub Actions workflow
- name: Run PostBuild Analyzer
  run: |
    python analyzer/postbuild_analyzer.py . \
      --build-log reports/build.log \
      --test-results reports/test_results.json \
      --coverage-report reports/coverage_report.json \
      --static-analysis reports/static_analysis.json \
      --config config.yaml \
      --output-dir reports
```

Reports are automatically generated and can be:
- Archived as build artifacts
- Parsed for CI/CD decision making
- Posted to dashboards
- Sent to development teams via Slack/email

### Scenario 2: Local Development

```bash
# Developer runs analysis locally
python run_local_analysis.py .

# Opens human-readable report
open reports/human_report.md
```

Allows developers to catch issues before pushing to CI.

### Scenario 3: Post-Mortem Analysis

```bash
# Analyze a specific commit
python analyzer/postbuild_analyzer.py /path/to/repo \
  --commit-sha abc123def456 \
  --config config.yaml \
  --output-dir analysis_results
```

Useful for understanding what went wrong in a build.

### Scenario 4: Standards Enforcement

Configure coding_standards in config.yaml and all subsequent analyses will:
- Flag naming convention violations
- Report functions exceeding length limits
- Identify missing documentation
- Track compliance over time

## Report Formats

### Machine Report (JSON)

Used for automation, parsing, and integration:

```json
{
  "version": "1.0.0",
  "repository": "https://github.com/org/repo",
  "ref": "abc123",
  "timestamp_utc": "2026-01-27T10:00:00Z",
  "overall_status": "warning",
  "build_summary": {
    "build_status": "success",
    "build_log_excerpt": "..."
  },
  "tests": {
    "total": 10,
    "passed": 9,
    "failed": 1,
    "skipped": 0,
    "failures": [...]
  },
  "coverage": {
    "overall_percent": 82.5,
    "files_below_threshold": [...]
  },
  "findings": [
    {
      "id": "std_001",
      "title": "Coding Standard: Function exceeds 50 lines",
      "category": "maintainability",
      "severity": "medium",
      "description": "Function 'process_data' has 67 lines, exceeds limit of 50",
      "evidence": [
        {
          "file": "src/sample_module.py",
          "line": 42,
          "excerpt": "def process_data(...):"
        }
      ],
      "recommendation": "Consider breaking this function into smaller, focused functions",
      "confidence": 0.75
    }
  ],
  "metadata": {
    "analysis_duration_seconds": 2.34,
    "agent_version": "1.0.0"
  }
}
```

### Human Report (Markdown)

Developer-friendly report with formatting and recommendations:

```markdown
# Post-Build Code Analysis Report

**Repository:** https://github.com/org/repo
**Commit:** abc123
**Timestamp:** 2026-01-27T10:00:00Z

## Status: ğŸŸ¡ **WARNING**

## Quick Summary
- **Build:** success
- **Tests:** 9/10 passed (90%)
- **Coverage:** 82.5%
- **Issues Found:** 12

## Findings by Severity

### CRITICAL (1)
**Failing test: test_authentication_flow**
- Category: bug
- Confidence: 100%
- Test failed with authentication module timeout

### HIGH (3)
...

## Recommended Actions

1. **Fix failing test** (critical)
   - Review test logs for timeout issues
   
2. **Increase coverage in auth.py** (high)
   - Currently at 65%, target is 80%

3. **Refactor process_data function** (medium)
   - Function exceeds 50 line limit at 67 lines

## Detailed Findings

### Finding 1: Failing test: test_authentication_flow
...
```

## Getting Started

### Installation

```bash
# Clone repository
git clone https://github.com/org/postbuild-analyzer.git
cd postbuild-analyzer

# Install dependencies
pip install -r requirements.txt
```

### Running Analysis

```bash
# Option 1: Quick start with sample project
python run_local_analysis.py .

# Option 2: Custom repository
python analyzer/postbuild_analyzer.py /path/to/repo \
  --config config.yaml \
  --output-dir ./reports

# Option 3: With all sources
python analyzer/postbuild_analyzer.py . \
  --build-log reports/build.log \
  --test-results reports/test_results.json \
  --coverage-report reports/coverage_report.json \
  --static-analysis reports/static_analysis.json \
  --config config.yaml
```

### Viewing Results

```bash
# Human-readable report
cat reports/human_report.md

# Machine-readable report
cat reports/machine_report.json | jq '.'
```

## Configuration Guide

### Essential Settings

```yaml
# Code quality thresholds
coverage_threshold: 80                # Required coverage percentage
complexity_threshold: 10              # Max cyclomatic complexity

# Feature enablement
enable_coding_standards_check: true   # Check naming, docstrings, etc.
enable_security_scan: true            # Include security vulnerabilities
enable_coverage_analysis: true        # Check coverage gaps
```

### Coding Standards Configuration

```yaml
coding_standards:
  # Function/method standards
  max_function_lines: 50              # Maximum function length
  max_function_complexity: 10         # Maximum cyclomatic complexity
  max_nested_levels: 4                # Maximum nesting depth
  
  # Naming conventions (regex patterns)
  naming_conventions:
    class_pattern: "^[A-Z][a-zA-Z0-9]*$"
    function_pattern: "^[a-z_][a-z0-9_]*$"
    constant_pattern: "^[A-Z_][A-Z0-9_]*$"
  
  # Documentation
  docstring_required: true            # Require docstrings
  
  # File standards
  max_file_lines: 500                 # Maximum file length
  trailing_whitespace: false          # Fail on trailing whitespace
  tabs_not_allowed: true              # Require spaces over tabs
  
  # Severity mappings
  violation_severities:
    max_function_lines: "medium"
    naming_convention: "low"
    missing_docstring: "low"
```

### Customization Examples

**Strict Standards** (e.g., financial systems):
```yaml
coverage_threshold: 95
max_function_lines: 30
docstring_required: true
max_nested_levels: 2
```

**Relaxed Standards** (e.g., quick prototypes):
```yaml
coverage_threshold: 60
max_function_lines: 100
docstring_required: false
max_nested_levels: 5
```

## Integration Examples

### GitHub Actions

```yaml
- name: Run PostBuild Analyzer
  run: |
    python analyzer/postbuild_analyzer.py . \
      --config config.yaml \
      --output-dir reports

- name: Upload reports
  uses: actions/upload-artifact@v4
  if: always()
  with:
    name: analysis-reports
    path: reports/
```

### Slack Notification

```python
import json
from pathlib import Path

report = json.loads(Path("reports/machine_report.json").read_text())

message = f"""
Code Analysis Report: {report['overall_status']}
Tests: {report['tests']['passed']}/{report['tests']['total']} passed
Coverage: {report['coverage']['overall_percent']:.1f}%
Issues: {len(report['findings'])}
"""

# Send to Slack webhook
```

### Dashboard Integration

The JSON report can be easily parsed and displayed in:
- Custom dashboards
- Grafana/Prometheus
- DataDog
- Splunk
- Any BI tool

## Troubleshooting

### Common Issues

**Q: Analysis runs but finds no issues**
- A: Check that input files exist and are valid JSON
- Ensure config.yaml has `enable_*_checks` set to true
- Verify Python files are in expected locations

**Q: High memory usage on large repositories**
- A: The analyzer limits file scanning to 50 files by default
- Modify `_analyze_coding_standards()` to reduce limit if needed

**Q: Config changes not taking effect**
- A: Ensure `--config config.yaml` is passed to the analyzer
- Use `python run_local_analysis.py .` to auto-load config.yaml

**Q: Report doesn't include security issues**
- A: Verify bandit is installed: `pip install bandit`
- Check `enable_security_scan: true` in config
- Ensure static_analysis.json contains security data

## Performance Characteristics

| Task | Time | Notes |
|------|------|-------|
| Full analysis | ~2-5 seconds | Depends on project size |
| Coding standards check | ~1 second | AST parsing + file scan |
| Report generation | ~0.5 seconds | JSON/Markdown formatting |
| Report upload | ~1 second | Network dependent |

## Future Enhancements

Planned features for future versions:

- **Trend Analysis**: Track metrics over time
- **Comparative Reports**: Compare against previous builds
- **Auto-Fixes**: Automatically fix style violations
- **PR Comments**: Post findings directly on GitHub PRs
- **Performance Profiling**: Identify performance bottlenecks
- **Architecture Analysis**: Dependency and coupling analysis
- **Documentation Generation**: Auto-generate API docs
- **ML-Based Detection**: Use ML for advanced pattern detection

## Support & Contributing

For issues, questions, or contributions:
- Open an issue on GitHub
- Check existing documentation
- Review example configurations
- Run analysis on sample_project for testing

## License

This project is licensed under the MIT License.

---

**Last Updated**: January 27, 2026
**Documentation Version**: 1.0.0
**Compatible With**: PostBuild Analyzer v1.0.0+
